#!/usr/bin/env python3
import rcl_interfaces.msg
import rclpy
from rcl_interfaces.msg import (FloatingPointRange, IntegerRange,
                                ParameterDescriptor, ParameterType)
from rclpy.node import Node
from rclpy.parameter import Parameter

import tf_transformations
import tf2_geometry_msgs
from geometry_msgs.msg import PoseStamped, PoseWithCovarianceStamped, TwistWithCovarianceStamped
from apriltag_ros.msg import AprilTagDetectionArray
from sensor_msgs.msg import Imu

from visual_localization.ekf import ExtendedKalmanFilter, MeasurementModelDistances, ProcessModel, EkfParams

import numpy as np
import yaml


class EkfNode(Node):

    def __init__(self, node_name):
        super().__init__(node_name=node_name)
        self.ekf_params = EkfParams()
        self.init_params()

        self.t_last_prediction = self.get_clock().now()
        self.tags = self.load_tag_poses()

        self.ekf = ExtendedKalmanFilter(self.ekf_params)

        self.vision_pose_pub = self.create_publisher(
            PoseWithCovarianceStamped,
            'mavros/vision_pose/pose_cov',
            qos_profile=1)

        # publish all ekf states? -> TODO

        # self.tag_detections_sub = self.create_subscription(
        #     AprilTagDetectionArray,
        #     'tag_detections',
        #     self.on_tag_detections,
        #     qos_profile=1)

        # self.orientation_sub = self.create_subscription(
        #     PoseStamped,
        #     'mavros/local_position/pose',
        #     self.on_orientation,
        #     qos_profile=1)

        # self.predict_timer = self.create_timer(timer_period_sec=(1 / 30),
        #                                        callback=self.predict)
        # self.send_vision_pose_timer = self.create_timer(
        #     timer_period_sec=(1 / 30), callback=self.send_vision_pose)

    def init_params(self):
        # general parameters
        self.declare_parameter(namespace='',
                               parameters=[('vehicle_name'),
                                           ('camera_name', 'vertical_camera')])
        # initial state
        self.declare_parameter(namespace='',
                               parameters=[('x0.x'), ('x0.y'), ('x0.z'),
                                           ('x0.roll'), ('x0.pitch'),
                                           ('x0.yaw'), ('x0.dx'), ('x0.dy'),
                                           ('x0.dz'), ('x0.droll'),
                                           ('x0.dpitch'), ('x0.dyaw')])
        # initial state covariance params
        self.declare_parameter(namespace='',
                               parameters=[('P0.x'), ('P0.y'), ('P0.z'),
                                           ('P0.roll'), ('P0.pitch'),
                                           ('P0.yaw'), ('P0.dx'), ('P0.dy'),
                                           ('P0.dz'), ('P0.dpitch'),
                                           ('P0.droll'), ('P0.dyaw')])

        # process noise
        self.declare_parameter(namespace='',
                               parameters=[('process_noise.x'),
                                           ('process_noise.y'),
                                           ('process_noise.z'),
                                           ('process_noise.roll'),
                                           ('process_noise.pitch'),
                                           ('process_noise.yaw'),
                                           ('process_noise.dx'),
                                           ('process_noise.dy'),
                                           ('process_noise.dz'),
                                           ('process_noise.droll'),
                                           ('process_noise.dpitch'),
                                           ('process_noise.dyaw')])

        # measurement noise
        self.declare_parameter(namespace='',
                               parameters=[('measurement_noise.distance'),
                                           ('measurement_noise.yaw')])

        self.declare_parameter(namespcae='',
                               parameters=[
                                   ('measurement_noise_orientation.roll',
                                    'measurement_noise_orientation.pitch')
                               ])

        # measurement noise orientation
        self.declare_parameter(namespace='', parameters=[()])

    def init_ekf_params(self):

        # param_names_process_noise = self.ekf_params.process_noise.__annotations__.keys(
        # )
        for name in self.ekf_params.process_noise.__annotations__.keys():
            full_name = f'process_noise.{name}'
            self.ekf_params.process_noise.__setattr__(
                name,
                self.get_parameter(full_name).value)

        # self.ekf_params.process_noise.x = self.get_parameter(
        #     'process_noise.x').value

    def on_tag_detections(self, msg: AprilTagDetectionArray):
        num_detected_tags = len(msg.detections)

        if num_detected_tags:
            # measurement for each tag consists of distance and yaw angle
            # -> dim_meas = 2
            measurements = np.zeros((num_detected_tags * self.ekf.dim_meas, 1))
            detected_tags = np.zeros((num_detected_tags, 4))

            for i, tag in enumerate(msg.detections):
                tag_id = int(tag.id[0])

                # add this tag's information to list of detected tags
                index = np.where(self.tags[:, 0] == tag_id)
                detected_tags[i, :] = self.tags[index, 0:4]

                # tranform tag pose
                transform = self.tf_helper.\
                    get_camera_frame_to_base_link_tf(self.camera_name)
                tag_pose_in_base_link = tf2_geometry_msgs.do_transform_pose(
                    tag.pose.pose, transform)

                position_tag_in_base_link = np.array([
                    tag_pose_in_base_link.pose.position.x,
                    tag_pose_in_base_link.pose.position.y,
                    tag_pose_in_base_link.pose.position.z
                ]).reshape(-1, 1)
                orientation = [
                    tag_pose_in_base_link.pose.orientation.x,
                    tag_pose_in_base_link.pose.orientation.y,
                    tag_pose_in_base_link.pose.orientation.z,
                    tag_pose_in_base_link.pose.orientation.w
                ]

                # inverse quaternion to get base_link orientation
                # in tag frame, which has same orientation as map frame
                orientation = tf_transformations.quaternion_inverse(
                    orientation)
                _, _, yaw = tf_transformations.euler_from_quaternion(
                    orientation)

                # measurement 1: distance tag - base_link
                measurements[self.ekf.dim_meas * i,
                             0] = np.linalg.norm(position_tag_in_base_link)
                # measurement 2: yaw angle in map frame
                measurements[self.ekf.dim_meas * i + 1, 0] = yaw

            self.ekf.updated_vision_data(measurements, detected_tags)

    def on_orientation(self, msg: PoseStamped):
        orientation = [
            msg.pose.orientation.x, msg.pose.orientation.y,
            msg.pose.orientation.z, msg.pose.orientation.w
        ]
        roll, pitch, _ = tf_transformations.euler_from_quaternion(orientation)
        measurements = np.array([roll, pitch]).reshape((-1, 1))

        self.ekf.update_orientation_data(measurements)

    def predict(self):
        now = self.get_clock().now()
        self.ekf.predict(now - self.t_last_prediction)

    def send_vision_pose(self):
        x_est = self.ekf.get_x_est()
        cov_est = self.ekf.get_p_mat()[:6, :6]
        quat = tf_transformations.quaternion_from_euler(x_est[3:5])

        msg = PoseWithCovarianceStamped()
        msg.header.stamp = self.get_clock().now().to_msg()
        msg.header.frame_id = 'map'
        msg.pose.pose.position.x = x_est[0]
        msg.pose.pose.position.y = x_est[1]
        msg.pose.pose.position.z = x_est[2]
        msg.pose.pose.orientation.x = quat[0]
        msg.pose.pose.orientation.y = quat[1]
        msg.pose.pose.orientation.z = quat[2]
        msg.pose.pose.orientation.w = quat[3]
        msg.pose.covariance = np.array.tolist(np.ndarray.flatten(cov_est))
        self.vision_pose_pub.publish(msg)

    def load_tag_poses(self):
        self.declare_parameter('tag_poses_file')
        filepath = self.get_parameter('tag_poses_file').value

        with open(filepath, 'r') as f:
            data = yaml.safe_load(f)
            num_tags = len(data['tag_poses'])

            # iterate over tags:
            tags = np.zeros((num_tags, 8))
            for tag in data['tag_poses']:
                if tag['frame_id'] == 'map':
                    tags[tag['id'], :] = np.array([
                        tag['id'], tag['x'], tag['y'], tag['z'], tag['qx'],
                        tag['qy'], tag['qz'], tag['qw']
                    ])
                else:
                    print('Tag not in map frame! - not implemented yet')
        return tags


def main():
    rclpy.init()
    node = EkfNode("ekf_node")
    rclpy.spin(node)


if __name__ == "__main__":
    main()
